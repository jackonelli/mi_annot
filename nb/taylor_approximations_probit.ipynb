{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, log2\n",
    "from scipy.stats import norm, bernoulli\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def h(p):\n",
    "    # Set h = 0 in the limit p -> 0, and p -> 1\n",
    "    entropy = np.empty(p.shape)\n",
    "    one_lim = np.isclose(p, 1.0)\n",
    "    zero_lim = np.isclose(p, 0.0)\n",
    "    limit_inds = np.logical_or(one_lim, zero_lim)\n",
    "    entropy[limit_inds] = 0\n",
    "    # For the rest, compute it the usual way.\n",
    "    ok_inds = np.logical_not(limit_inds)\n",
    "    ok_p = p[ok_inds]\n",
    "    entropy[ok_inds] = -ok_p*np.log2(ok_p) - (1-ok_p)*np.log2(1-ok_p)\n",
    "    return entropy\n",
    "\n",
    "def p(z, alpha=0.9):\n",
    "    return (2*alpha - 1)*norm.cdf(z) + 1-alpha\n",
    "\n",
    "def mc_approx(x, alpha, num_terms=10000):\n",
    "    theta_samples = norm.rvs(size=num_terms)\n",
    "    z = x * theta_samples\n",
    "    probit_val = norm.cdf(z)\n",
    "    #print(probit_val.max())\n",
    "    entropies = h(p(z, alpha))\n",
    "    return entropies.mean()\n",
    "\n",
    "alpha = 1.0\n",
    "xs = np.linspace(-10, 10, 1000)\n",
    "mc_mis = [mc_approx(x, alpha) for x in xs]\n",
    "plt.plot(xs, mc_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "def analytical(x, theta, alpha):\n",
    "    return h(p(x*theta, alpha))\n",
    "\n",
    "def taylor_approx(x, theta, alpha):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    return np.exp(- (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2)\n",
    "\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "fig, ax = plt.subplots()\n",
    "x = 1\n",
    "alpha = 0.7\n",
    "ax.plot(thetas, analytical(thetas, x, alpha), label=\"Exact\")\n",
    "ax.plot(thetas, taylor_approx(thetas, x, alpha), '--', label=\"Taylor\")\n",
    "ax.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"h\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical(x, theta, alpha):\n",
    "    return h(p(x*theta, alpha))\n",
    "\n",
    "def taylor_approx(x, theta, alpha):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    if np.isclose(alpha, 0.5):\n",
    "        print(\"limit\")\n",
    "        return np.ones(x.shape)\n",
    "    alpha_entropy = h(np.atleast_1d(alpha)).item()\n",
    "    constant_term = np.log(1 - alpha_entropy)\n",
    "    factor_1 = 1 / (1 - np.log(alpha))\n",
    "    factor_2 = - (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2\n",
    "    return np.exp(constant_term + factor_1*factor_2) + alpha_entropy\n",
    "\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "fig, ax = plt.subplots()\n",
    "x = 0.5\n",
    "alpha = 0.8\n",
    "ax.plot(thetas, analytical(thetas, x, alpha), label=\"Exact\")\n",
    "ax.plot(thetas, taylor_approx(thetas, x, alpha), '--', label=\"Taylor\")\n",
    "ax.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"h\")\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bernoulli.rvs(p=0.5, size=10)\n",
    "b = bernoulli.rvs(p=0.5, size=10)\n",
    "c = np.logical_or(a,b)\n",
    "for x, y, z in zip(a, b, c):\n",
    "    print(x, y, z)\n",
    "    \n",
    "np.isclose(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_analytical(theta, y_tildes, xs, alphas):\n",
    "    trues = y_tildes == 1\n",
    "    falses = y_tildes == 0\n",
    "    true_terms = np.log(p(xs[trues] * theta, alphas[trues]))\n",
    "    false_terms = np.log(1 - p(xs[falses] * theta, alphas[falses]))\n",
    "    return np.exp(true_terms.sum() + false_terms.sum())\n",
    "\n",
    "def multi_taylor_approx(theta, y_tildes, xs, alphas):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    trues = y_tildes == 1\n",
    "    falses = y_tildes == 0\n",
    "    true_terms = ( alphas[trues] - 1 )**2 * xs[trues]**2\n",
    "    false_terms = (1 - p(xs[falses] * theta, alphas[falses]))\n",
    "    inv_cov = \n",
    "    return np.exp(- (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2)\n",
    "\n",
    "num_samples = 10\n",
    "y_tildes = bernoulli.rvs(p=0.5, size=num_samples)\n",
    "xs = norm.rvs(size=num_samples)\n",
    "alphas = np.ones(xs.shape)\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "entropies = np.array([multi_analytical(theta, y_tildes, xs, alphas) for theta in thetas])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thetas, entropies, label=\"Exact\")\n",
    "# ax.plot(thetas, taylor_approx(thetas, x, alpha), '--', label=\"Taylor\")\n",
    "ax.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"h\")\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_annot",
   "language": "python",
   "name": "mi_annot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
