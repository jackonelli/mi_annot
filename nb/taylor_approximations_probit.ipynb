{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ae9c00",
   "metadata": {},
   "source": [
    "# MI-term: $\\mathbb{E}_{\\Theta \\sim p(\\Theta \\vert X_{1:n})} \\left[\\mathcal{H}[\\tilde{Y}_{1:n} \\vert \\Theta, X_{1:n}] \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose, log, log2\n",
    "from scipy.stats import norm, bernoulli\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def h(p):\n",
    "    # Set h = 0 in the limit p -> 0, and p -> 1\n",
    "    entropy = np.empty(p.shape)\n",
    "    one_lim = np.isclose(p, 1.0)\n",
    "    zero_lim = np.isclose(p, 0.0)\n",
    "    limit_inds = np.logical_or(one_lim, zero_lim)\n",
    "    entropy[limit_inds] = 0\n",
    "    # For the rest, compute it the usual way.\n",
    "    ok_inds = np.logical_not(limit_inds)\n",
    "    ok_p = p[ok_inds]\n",
    "    entropy[ok_inds] = -ok_p*np.log2(ok_p) - (1-ok_p)*np.log2(1-ok_p)\n",
    "    return entropy\n",
    "\n",
    "def h_(p):\n",
    "    # Set h = 0 in the limit p -> 0, and p -> 1\n",
    "    if isclose(p, 1.0) or isclose(p, 0.0):\n",
    "        entropy = 0\n",
    "    else:\n",
    "    # For the rest, compute it the usual way.\n",
    "        entropy = -p*np.log2(p) - (1-p)*np.log2(1-p)\n",
    "    return entropy\n",
    "\n",
    "def h_arr(p_arr):\n",
    "    return np.array([h_(p) for p in p_arr])\n",
    "\n",
    "def p(z, alpha_i=0.9):\n",
    "    \"\"\"Likelihood p(Ỹ_i = ỹ_i | Theta = theta, X_i = x_i),\n",
    "    with z = theta^T x_i\n",
    "    \"\"\"\n",
    "    return (2*alpha_i - 1)*norm.cdf(z) + 1-alpha_i\n",
    "\n",
    "def mc_approx(x, alpha, num_terms=100):\n",
    "    theta_samples = norm.rvs(size=num_terms)\n",
    "    z = x * theta_samples\n",
    "    probit_val = norm.cdf(z)\n",
    "    #print(probit_val.max())\n",
    "    entropies = h(p(z, alpha))\n",
    "    return entropies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366af24",
   "metadata": {},
   "source": [
    "## Taylor approximation of $ln(h((2\\alpha_i - 1)\\Phi(\\theta x_i) + 1 - \\alpha_i))$\n",
    "This is the same approx. as in BALD, with the added $\\alpha_i$ label noise.\n",
    "Results in a poor fit as the approximation goes to zero in the extremes, even in the presence of label noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a1ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "def analytical(x, theta, alpha):\n",
    "    return h(p(x*theta, alpha))\n",
    "\n",
    "def taylor_approx(x, theta, alpha):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    return np.exp(- (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2)\n",
    "\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "fig, ax = plt.subplots()\n",
    "x = 1\n",
    "alpha = 0.7\n",
    "ax.plot(thetas, analytical(thetas, x, alpha), label=\"Exact\")\n",
    "ax.plot(thetas, taylor_approx(thetas, x, alpha), '--', label=\"Taylor\")\n",
    "ax.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"h\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6ee58",
   "metadata": {},
   "source": [
    "## Taylor approximation of difference $ln(h((2\\alpha_i - 1)\\Phi(\\theta x_i) + 1 - \\alpha_i) - h(\\alpha_i))$\n",
    "\n",
    "Let $h(...) = h(...) - h(\\alpha_i) + h(\\alpha_i)$ and only approximate the first two terms.\n",
    "The result is an entropy approx. that decays to $h(\\alpha_i)$ in the extremes and gives BALD-like quality of fit for every label precision $\\alpha_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_approx(x, theta, alpha):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    if np.isclose(alpha, 0.5):\n",
    "        return np.ones(x.shape)\n",
    "    alpha_entropy = h(np.atleast_1d(alpha)).item()\n",
    "    constant_term = np.log(1 - alpha_entropy)\n",
    "    factor_1 = 1 / (1 - alpha_entropy)\n",
    "    factor_2 = - (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2\n",
    "    return np.exp(constant_term + factor_1*factor_2) + alpha_entropy\n",
    "\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "x = 1.0\n",
    "alpha = 0.7\n",
    "analytical_h = analytical(thetas, x, alpha)\n",
    "taylor_h = taylor_approx(thetas, x, alpha)\n",
    "\n",
    "fig, ax_1 = plt.subplots()\n",
    "analytical_l = ax_1.plot(thetas, analytical_h, label=\"Exact\")\n",
    "taylor_l = ax_1.plot(thetas, taylor_h, \"--\", label=\"Taylor\")\n",
    "ax_1.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax_1.set_xlabel(\"t\")\n",
    "ax_1.set_ylabel(\"h\")\n",
    "ax_2 = ax_1.twinx()\n",
    "abs_err_l = ax_2.plot(thetas, np.abs(analytical_h - taylor_h), linestyle=\"dotted\", color=\"black\",label=\"abs err\")\n",
    "ax_2.set_ylabel(\"err\")\n",
    "lns = analytical_l + taylor_l + abs_err_l\n",
    "labels = [l.get_label() for l in lns]\n",
    "plt.legend(lns, labels, loc=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33243630",
   "metadata": {},
   "source": [
    "# MI-term: $\\mathcal{H}[\\tilde{Y}_{1:n} \\vert X_{1:n}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f880282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_y_tilde_seq_theta(y_tilde_seq, x_seq, theta, alpha_seq):\n",
    "    \"\"\"Likelihood p(Ỹ_1:n = ỹ_1:n | Theta = theta, X_1:n = x_1:n)\n",
    "    \n",
    "    Args:\n",
    "        y_tilde_seq (np.array): Seq. of Bernoulli variables (n,): {0, 1}^n\n",
    "        x_seq (np.array): Seq. of np.arrays (n, D_x)\n",
    "        theta (np.array): Vector (D_x,)\n",
    "        alpha_seq (np.array): Seq of prec. values (n,): [0.5, 1]^n\n",
    "        \n",
    "    \"\"\"\n",
    "    true_inds = y_tilde_seq == 1\n",
    "    false_inds = y_tilde_seq == 0\n",
    "    z = theta @ x_seq.T\n",
    "    true_prod = p(z[true_inds], alpha_seq[true_inds])\n",
    "    false_prod = 1 - p(z[false_inds], alpha_seq[false_inds])\n",
    "    return true_prod.prod() * false_prod.prod()\n",
    "\n",
    "def p_y_tilde_seq_taylor(y_tilde_seq, x_seq, theta, alpha_seq):\n",
    "    \"\"\"Approximate likelihood p_hat(Ỹ_1:n = ỹ_1:n | Theta = theta, X_1:n = x_1:n)\n",
    "    \n",
    "    Args:\n",
    "        y_tilde_seq (np.array): Seq. of Bernoulli variables (n,): {0, 1}^n\n",
    "        x_seq (np.array): Seq. of np.arrays (n, D_x)\n",
    "        theta (np.array): Vector (D_x,)\n",
    "        alpha_seq (np.array): Seq of prec. values (n,): [0.5, 1]^n\n",
    "        \n",
    "    \"\"\"\n",
    "    n = y_tilde_seq.shape[0]\n",
    "    constant_term = n * np.log(2)\n",
    "    inv_cov = (alpha_seq * x_seq.T) @ x_seq / np.pi\n",
    "    quad_term = theta.T @ inv_cov @ theta\n",
    "    return np.exp(-(constant_term + quad_term))\n",
    "    \n",
    "\n",
    "    \n",
    "n = 10\n",
    "D_x = 1\n",
    "x_seq = np.random.normal(loc=0, scale=10, size=(n, D_x))\n",
    "y_tilde_seq = bernoulli.rvs(p=0.5, size=n)\n",
    "# y_tilde_seq = bernoulli.rvs(p=norm.cdf(x_seq).reshape((n,)))\n",
    "thetas = np.atleast_2d(np.linspace(-1, 1, 1000)).T\n",
    "exact_ps = [p_y_tilde_seq_theta(y_tilde_seq, x_seq, theta, np.ones((n,))) for theta in thetas]\n",
    "taylor_ps = [p_y_tilde_seq_taylor(y_tilde_seq, x_seq, theta, np.ones((n,))) for theta in thetas]\n",
    "\n",
    "fig, ax_1 = plt.subplots()\n",
    "exact_l = ax_1.plot(thetas, exact_ps, label=\"Exact\")\n",
    "taylor_l = ax_1.plot(thetas, taylor_ps, \"--\", label=\"Taylor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x_seq = np.random.normal(loc=0, scale=10, size=(n, D_x))\n",
    "y_tilde_seq = bernoulli.rvs(p=norm.cdf(x_seq).reshape((n,)))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_seq, y_tilde_seq, \"*\")\n",
    "#y_tilde_seq = bernoulli.rvs(p=0.5, size=n)\n",
    "y_tilde_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_analytical(theta, y_tildes, xs, alphas):\n",
    "    trues = y_tildes == 1\n",
    "    falses = y_tildes == 0\n",
    "    true_terms = np.log(p(xs[trues] * theta, alphas[trues]))\n",
    "    false_terms = np.log(1 - p(xs[falses] * theta, alphas[falses]))\n",
    "    return np.exp(true_terms.sum() + false_terms.sum())\n",
    "\n",
    "def multi_taylor_approx(theta, y_tildes, xs, alphas):\n",
    "    \"\"\"Taylor approximation of ln(h(p(theta, x)))\"\"\"\n",
    "    trues = y_tildes == 1\n",
    "    falses = y_tildes == 0\n",
    "    true_terms = ( alphas[trues] - 1 )**2 * xs[trues]**2\n",
    "    false_terms = (1 - p(xs[falses] * theta, alphas[falses]))\n",
    "    inv_cov = \n",
    "    return np.exp(- (2 * alpha - 1)**2 / (np.pi * np.log(2)) * (theta*x)**2)\n",
    "\n",
    "num_samples = 10\n",
    "y_tildes = bernoulli.rvs(p=0.5, size=num_samples)\n",
    "xs = norm.rvs(size=num_samples)\n",
    "alphas = np.ones(xs.shape)\n",
    "thetas = np.linspace(-10, 10, 1000)\n",
    "entropies = np.array([multi_analytical(theta, y_tildes, xs, alphas) for theta in thetas])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thetas, entropies, label=\"Exact\")\n",
    "# ax.plot(thetas, taylor_approx(thetas, x, alpha), '--', label=\"Taylor\")\n",
    "ax.set_title(\"$h[(2a -1)F(t x) + 1 - a]$\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"h\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01eb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
